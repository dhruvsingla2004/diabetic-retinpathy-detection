{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQhyZwYpchoa"
      },
      "outputs": [],
      "source": [
        "import numpy as np        #importing moduls\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9lMA2pYchoh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import cv2\n",
        "# import albumentations as albu\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from pylab import rcParams\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgGmPxmhchoi"
      },
      "outputs": [],
      "source": [
        "img_size = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSv6eoSBchoi"
      },
      "outputs": [],
      "source": [
        "path = 'D:/train_data/train/train' \n",
        "# output_path_folder = ''\n",
        "\n",
        "path_index=\"D:/train_data/trainLabels.csv\"\n",
        "count=0\n",
        "images_arrays=[]\n",
        "resized_images=[]\n",
        "\n",
        "\n",
        "\n",
        "data=pd.read_csv(path_index)   #reducing data \n",
        "\n",
        "data_0=data[data['level']==0]\n",
        "data_0=data_0.head(1000)\n",
        "\n",
        "data_1=data[data['level']==1]\n",
        "data_1=data_1.head(1000)\n",
        "\n",
        "data_2=data[data['level']==2]\n",
        "data_2=data_2.head(1100)\n",
        "\n",
        "data_3=data[data['level']==3]\n",
        "data_4=data[data['level']==4]\n",
        "\n",
        "labels_used=pd.concat([data_0,data_1,data_2,data_0,data_1,data_2,data_3,data_4,data_3,data_4])\n",
        "labels_used=labels_used.sample(frac=1,random_state=42)   #shuffling data\n",
        "actual_labels=labels_used['level']\n",
        "labels_used=labels_used['image']\n",
        "actual_labels=np.array(actual_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbnRbf-Kchoj"
      },
      "outputs": [],
      "source": [
        "y_train_true=[]  #1-hot encoding\n",
        "for i in actual_labels:\n",
        "    l=np.zeros(5)\n",
        "    l[i]=1\n",
        "    y_train_true.append(l)\n",
        "y_train_true=np.array(y_train_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl6li5vpchok"
      },
      "outputs": [],
      "source": [
        "# resized_images=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xRthpDschol",
        "outputId": "ef5f6808-fab0-40a3-acff-e6f4738f0d5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\train_data\\mobilnet_best_58 copy.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/train_data/mobilnet_best_58%20copy.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m final_img \u001b[39m=\u001b[39m clahe\u001b[39m.\u001b[39mapply(image_bw)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/train_data/mobilnet_best_58%20copy.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# plt.imshow(final_img)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/train_data/mobilnet_best_58%20copy.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# plt.show()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/train_data/mobilnet_best_58%20copy.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/train_data/mobilnet_best_58%20copy.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#finding ends for croping\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/train_data/mobilnet_best_58%20copy.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m img_processed \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39;49marray(final_img)\u001b[39m-\u001b[39;49m\u001b[39m6\u001b[39;49m)\u001b[39m/\u001b[39;49m\u001b[39m255\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/train_data/mobilnet_best_58%20copy.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m variance\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/train_data/mobilnet_best_58%20copy.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m col_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(img_processed, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# image preprocessing\n",
        "\n",
        "count = 0\n",
        "for img in labels_used:\n",
        "    img=img+'.jpeg'\n",
        "    bgr_img = cv2.imread(os.path.join(path,img))\n",
        "    # bgr_img = cv2.resize(bgr_img, (img_size,img_size))\n",
        "    image_bw = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)  #making images black and white\n",
        "    # hsv_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV)\n",
        "    rbg_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # gray_three = cv2.merge([image_bw,image_bw,image_bw])\n",
        "    # hsv_img = cv2.cvtColor(rbg_img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit = 5)  #increasing contrast\n",
        "    final_img = clahe.apply(image_bw)\n",
        "\n",
        "    # plt.imshow(final_img)\n",
        "    # plt.show()\n",
        "    \n",
        "    #finding ends for croping\n",
        "    img_processed = (np.array(final_img)-6)/255  #removing a reductant purple layer\n",
        "    variance=1\n",
        "    col_sum = np.sum(img_processed, axis=0)  #Cropping of free space\n",
        "    row_sum = np.sum(img_processed, axis=1)\n",
        "    coordx = []\n",
        "    coordy = []\n",
        "    for i,j in enumerate(col_sum):\n",
        "        if j>variance:\n",
        "            coordx.append(i)\n",
        "    for i,j in enumerate(row_sum):\n",
        "        if j>variance:\n",
        "            coordy.append(i)\n",
        "\n",
        "    final_img = final_img[coordy[0]:coordy[-1]:, coordx[0]:coordx[-1]]\n",
        "    \n",
        "    gray_three = cv2.merge([final_img,final_img,final_img])\n",
        "    gray_three = cv2.resize(gray_three, (img_size,img_size))\n",
        "    resized_images.append(gray_three)\n",
        "    count+=1\n",
        "    if (count%100==0):\n",
        "        print(count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ai58NQlVchon"
      },
      "outputs": [],
      "source": [
        "# resized_images2=np.array(resized_images)\n",
        "# np.save('x_train',resized_images2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSwL5aVxchon"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_train = np.load('x_train.npy')\n",
        "x_train = np.array(x_train, np.float32) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ehUj789choo"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential \n",
        "from tensorflow.keras.applications import ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka5eXudVchoo"
      },
      "outputs": [],
      "source": [
        "# np.save('y_train.npy',y_train_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8kBIw8kchop"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train2,x_valid,y_train,y_valid=train_test_split(x_train,y_train_true,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n24U56yochop"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.applications import VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZpA1Z0Gchop"
      },
      "outputs": [],
      "source": [
        "# model=Sequential()   #Building a sequential model and implimenting transfer learning\n",
        "# model_efficient=ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3),classes=5)\n",
        "# for layers in model_efficient.layers:\n",
        "#     layers.trainable=False\n",
        "\n",
        "# model.add(model_efficient)\n",
        "# model.add(MaxPool2D((2,2),padding='same'))\n",
        "# model.add(GlobalAveragePooling2D())\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fMairAIchoq"
      },
      "outputs": [],
      "source": [
        "# model=Sequential()\n",
        "# model_efficient=EfficientNetB7(weights='imagenet',include_top=False,input_shape=(260,260,3),classes=5)\n",
        "# for layers in model_efficient.layers:\n",
        "#     layers.trainable=False\n",
        "\n",
        "\n",
        "# model.add(model_efficient)\n",
        "# model.add(GlobalAveragePooling2D())\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "# model.summary()\n",
        "import tensorflow as tf\n",
        "model=tf.keras.models.load_model('accuracy_72p.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3opL5Etchoq",
        "outputId": "aa5396c6-26fc-47b6-c1ca-a1c2fcb640cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5702 - accuracy: 0.7737\n",
            "Epoch 1: val_accuracy improved from -inf to 0.70475, saving model to best_after74.h5\n",
            "150/150 [==============================] - 428s 3s/step - loss: 0.5702 - accuracy: 0.7737 - val_loss: 0.7565 - val_accuracy: 0.7048\n",
            "Epoch 2/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.7797\n",
            "Epoch 2: val_accuracy improved from 0.70475 to 0.73572, saving model to best_after74.h5\n",
            "150/150 [==============================] - 592s 4s/step - loss: 0.5606 - accuracy: 0.7797 - val_loss: 0.6906 - val_accuracy: 0.7357\n",
            "Epoch 3/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.7729\n",
            "Epoch 3: val_accuracy did not improve from 0.73572\n",
            "150/150 [==============================] - 645s 4s/step - loss: 0.5671 - accuracy: 0.7729 - val_loss: 0.7101 - val_accuracy: 0.7229\n",
            "Epoch 4/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5542 - accuracy: 0.7837\n",
            "Epoch 4: val_accuracy improved from 0.73572 to 0.74746, saving model to best_after74.h5\n",
            "150/150 [==============================] - 410s 3s/step - loss: 0.5542 - accuracy: 0.7837 - val_loss: 0.6706 - val_accuracy: 0.7475\n",
            "Epoch 5/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.7717\n",
            "Epoch 5: val_accuracy improved from 0.74746 to 0.76348, saving model to best_after74.h5\n",
            "150/150 [==============================] - 411s 3s/step - loss: 0.5782 - accuracy: 0.7717 - val_loss: 0.6551 - val_accuracy: 0.7635\n",
            "Epoch 6/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5609 - accuracy: 0.7733\n",
            "Epoch 6: val_accuracy did not improve from 0.76348\n",
            "150/150 [==============================] - 408s 3s/step - loss: 0.5609 - accuracy: 0.7733 - val_loss: 0.7029 - val_accuracy: 0.7448\n",
            "Epoch 7/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.7797\n",
            "Epoch 7: val_accuracy did not improve from 0.76348\n",
            "150/150 [==============================] - 409s 3s/step - loss: 0.5575 - accuracy: 0.7797 - val_loss: 0.6713 - val_accuracy: 0.7480\n",
            "Epoch 8/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7767\n",
            "Epoch 8: val_accuracy did not improve from 0.76348\n",
            "150/150 [==============================] - 410s 3s/step - loss: 0.5616 - accuracy: 0.7767 - val_loss: 0.6832 - val_accuracy: 0.7443\n",
            "Epoch 9/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5515 - accuracy: 0.7821\n",
            "Epoch 9: val_accuracy did not improve from 0.76348\n",
            "150/150 [==============================] - 322s 2s/step - loss: 0.5515 - accuracy: 0.7821 - val_loss: 0.6624 - val_accuracy: 0.7544\n",
            "Epoch 10/10\n",
            "150/150 [==============================] - ETA: 0s - loss: 0.5517 - accuracy: 0.7825\n",
            "Epoch 10: val_accuracy did not improve from 0.76348\n",
            "150/150 [==============================] - 324s 2s/step - loss: 0.5517 - accuracy: 0.7825 - val_loss: 0.6617 - val_accuracy: 0.7448\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x280f72c2790>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "# mc=ModelCheckpoint('best_after74.h5',monitor='val_accuracy',mode='max',verbose=1,save_best_only=True)\n",
        "# model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# model.fit(x_train2,y_train,validation_data=(x_valid,y_valid),verbose=1,callbacks=[es,mc],epochs=10,batch_size=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPujZSo3chos",
        "outputId": "a677c3d1-761c-4ab2-fa81-a4219ddff1a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59/59 [==============================] - 70s 1s/step\n"
          ]
        }
      ],
      "source": [
        "y_pred=model.predict(x_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDPbfJTFchos"
      },
      "outputs": [],
      "source": [
        "y_pred_net=[]\n",
        "for i in y_pred:\n",
        "    y_pred_net.append(np.argmax(i))\n",
        "y_pred_net=np.array(y_pred_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DEADPTrchos"
      },
      "outputs": [],
      "source": [
        "y_pred_t=[]\n",
        "for i in y_valid:\n",
        "    y_pred_t.append(np.argmax(i))\n",
        "y_pred_t=np.array(y_pred_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ulkSDXwchos",
        "outputId": "36d69856-554c-4b47-8968-82ae9c675b4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 4, ..., 1, 2, 2], dtype=int64)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvmbpnQechot",
        "outputId": "f2632863-717a-419a-bbf0-688dd3a0c2e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7271756540309664\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[229, 111,  29,  13,   5],\n",
              "       [ 44, 327,  16,  12,   0],\n",
              "       [ 59, 116, 223,  34,  10],\n",
              "       [ 10,  16,  15, 318,   3],\n",
              "       [  0,   6,   7,   5, 265]], dtype=int64)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_pred_t,y_pred_net))\n",
        "confusion_matrix(y_pred_t,y_pred_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e46XmA81chot",
        "outputId": "06c26b91-78f2-427f-cfe6-29e6667eb5be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkyUOwIfchot",
        "outputId": "bdb97807-8f66-4101-98e3-4a120276a38f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 54). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: accuracy_72p.model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: accuracy_72p.model\\assets\n"
          ]
        }
      ],
      "source": [
        "# model.save('accuracy_72p.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFRh8j4ichot"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFEsF5Sichou"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}